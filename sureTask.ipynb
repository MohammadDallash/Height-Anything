{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NvJ1Frjt-0Ux"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "xFormers not available\n",
            "xFormers not available\n"
          ]
        }
      ],
      "source": [
        "from ultralytics import YOLO\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from matplotlib.patches import Polygon\n",
        "import numpy as np\n",
        "import cv2\n",
        "import itertools\n",
        "from time import time\n",
        "import torch\n",
        "import supervision as sv\n",
        "from depth.depth_anything_v2.dpt import DepthAnythingV2\n",
        "from matplotlib.colors import Normalize\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "VIDEO_PATH = 'walking4.mp4'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1kjm91CLcQd",
        "outputId": "10239bec-2a1e-4848-99e4-713c630f7ccd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU is available. Using GPU.\n"
          ]
        }
      ],
      "source": [
        "# Check if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device('cuda')\n",
        "    print(\"GPU is available. Using GPU.\")\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "    print(\"GPU is not available. Using CPU.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Object Detection Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aO5LwNhl-qfv"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "YOLO(\n",
              "  (model): SegmentationModel(\n",
              "    (model): Sequential(\n",
              "      (0): Conv(\n",
              "        (conv): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (1): Conv(\n",
              "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "        (act): SiLU(inplace=True)\n",
              "      )\n",
              "      (2): RepNCSPELAN4(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Sequential(\n",
              "          (0): RepCSP(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv3): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (m): Sequential(\n",
              "              (0): RepBottleneck(\n",
              "                (cv1): RepConv(\n",
              "                  (act): SiLU(inplace=True)\n",
              "                  (conv1): Conv(\n",
              "                    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                    (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                  (conv2): Conv(\n",
              "                    (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                    (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1): Conv(\n",
              "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (cv3): Sequential(\n",
              "          (0): RepCSP(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv3): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (m): Sequential(\n",
              "              (0): RepBottleneck(\n",
              "                (cv1): RepConv(\n",
              "                  (act): SiLU(inplace=True)\n",
              "                  (conv1): Conv(\n",
              "                    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                    (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                  (conv2): Conv(\n",
              "                    (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                    (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1): Conv(\n",
              "            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (cv4): Conv(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (3): ADown(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (4): RepNCSPELAN4(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Sequential(\n",
              "          (0): RepCSP(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv3): Conv(\n",
              "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (m): Sequential(\n",
              "              (0): RepBottleneck(\n",
              "                (cv1): RepConv(\n",
              "                  (act): SiLU(inplace=True)\n",
              "                  (conv1): Conv(\n",
              "                    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                  (conv2): Conv(\n",
              "                    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1): Conv(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (cv3): Sequential(\n",
              "          (0): RepCSP(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv3): Conv(\n",
              "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (m): Sequential(\n",
              "              (0): RepBottleneck(\n",
              "                (cv1): RepConv(\n",
              "                  (act): SiLU(inplace=True)\n",
              "                  (conv1): Conv(\n",
              "                    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                  (conv2): Conv(\n",
              "                    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1): Conv(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (cv4): Conv(\n",
              "          (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (5): ADown(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (6): RepNCSPELAN4(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Sequential(\n",
              "          (0): RepCSP(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv3): Conv(\n",
              "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (m): Sequential(\n",
              "              (0): RepBottleneck(\n",
              "                (cv1): RepConv(\n",
              "                  (act): SiLU(inplace=True)\n",
              "                  (conv1): Conv(\n",
              "                    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                  (conv2): Conv(\n",
              "                    (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1): Conv(\n",
              "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (cv3): Sequential(\n",
              "          (0): RepCSP(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv3): Conv(\n",
              "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (m): Sequential(\n",
              "              (0): RepBottleneck(\n",
              "                (cv1): RepConv(\n",
              "                  (act): SiLU(inplace=True)\n",
              "                  (conv1): Conv(\n",
              "                    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                  (conv2): Conv(\n",
              "                    (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1): Conv(\n",
              "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (cv4): Conv(\n",
              "          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (7): ADown(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (8): RepNCSPELAN4(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Sequential(\n",
              "          (0): RepCSP(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv3): Conv(\n",
              "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (m): Sequential(\n",
              "              (0): RepBottleneck(\n",
              "                (cv1): RepConv(\n",
              "                  (act): SiLU(inplace=True)\n",
              "                  (conv1): Conv(\n",
              "                    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                  (conv2): Conv(\n",
              "                    (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1): Conv(\n",
              "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (cv3): Sequential(\n",
              "          (0): RepCSP(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv3): Conv(\n",
              "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (m): Sequential(\n",
              "              (0): RepBottleneck(\n",
              "                (cv1): RepConv(\n",
              "                  (act): SiLU(inplace=True)\n",
              "                  (conv1): Conv(\n",
              "                    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                  (conv2): Conv(\n",
              "                    (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1): Conv(\n",
              "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (cv4): Conv(\n",
              "          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (9): SPPELAN(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
              "        (cv3): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
              "        (cv4): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
              "        (cv5): Conv(\n",
              "          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (10): Upsample(scale_factor=2.0, mode='nearest')\n",
              "      (11): Concat()\n",
              "      (12): RepNCSPELAN4(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Sequential(\n",
              "          (0): RepCSP(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv3): Conv(\n",
              "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (m): Sequential(\n",
              "              (0): RepBottleneck(\n",
              "                (cv1): RepConv(\n",
              "                  (act): SiLU(inplace=True)\n",
              "                  (conv1): Conv(\n",
              "                    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                  (conv2): Conv(\n",
              "                    (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1): Conv(\n",
              "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (cv3): Sequential(\n",
              "          (0): RepCSP(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv3): Conv(\n",
              "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (m): Sequential(\n",
              "              (0): RepBottleneck(\n",
              "                (cv1): RepConv(\n",
              "                  (act): SiLU(inplace=True)\n",
              "                  (conv1): Conv(\n",
              "                    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                  (conv2): Conv(\n",
              "                    (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1): Conv(\n",
              "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (cv4): Conv(\n",
              "          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (13): Upsample(scale_factor=2.0, mode='nearest')\n",
              "      (14): Concat()\n",
              "      (15): RepNCSPELAN4(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Sequential(\n",
              "          (0): RepCSP(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv3): Conv(\n",
              "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (m): Sequential(\n",
              "              (0): RepBottleneck(\n",
              "                (cv1): RepConv(\n",
              "                  (act): SiLU(inplace=True)\n",
              "                  (conv1): Conv(\n",
              "                    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                  (conv2): Conv(\n",
              "                    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1): Conv(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (cv3): Sequential(\n",
              "          (0): RepCSP(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv3): Conv(\n",
              "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (m): Sequential(\n",
              "              (0): RepBottleneck(\n",
              "                (cv1): RepConv(\n",
              "                  (act): SiLU(inplace=True)\n",
              "                  (conv1): Conv(\n",
              "                    (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                  (conv2): Conv(\n",
              "                    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                    (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1): Conv(\n",
              "            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (cv4): Conv(\n",
              "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (16): ADown(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (17): Concat()\n",
              "      (18): RepNCSPELAN4(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Sequential(\n",
              "          (0): RepCSP(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv3): Conv(\n",
              "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (m): Sequential(\n",
              "              (0): RepBottleneck(\n",
              "                (cv1): RepConv(\n",
              "                  (act): SiLU(inplace=True)\n",
              "                  (conv1): Conv(\n",
              "                    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                  (conv2): Conv(\n",
              "                    (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1): Conv(\n",
              "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (cv3): Sequential(\n",
              "          (0): RepCSP(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv3): Conv(\n",
              "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (m): Sequential(\n",
              "              (0): RepBottleneck(\n",
              "                (cv1): RepConv(\n",
              "                  (act): SiLU(inplace=True)\n",
              "                  (conv1): Conv(\n",
              "                    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                  (conv2): Conv(\n",
              "                    (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1): Conv(\n",
              "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (cv4): Conv(\n",
              "          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (19): ADown(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Conv(\n",
              "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (20): Concat()\n",
              "      (21): RepNCSPELAN4(\n",
              "        (cv1): Conv(\n",
              "          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "        (cv2): Sequential(\n",
              "          (0): RepCSP(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv3): Conv(\n",
              "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (m): Sequential(\n",
              "              (0): RepBottleneck(\n",
              "                (cv1): RepConv(\n",
              "                  (act): SiLU(inplace=True)\n",
              "                  (conv1): Conv(\n",
              "                    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                  (conv2): Conv(\n",
              "                    (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1): Conv(\n",
              "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (cv3): Sequential(\n",
              "          (0): RepCSP(\n",
              "            (cv1): Conv(\n",
              "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv2): Conv(\n",
              "              (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (cv3): Conv(\n",
              "              (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (m): Sequential(\n",
              "              (0): RepBottleneck(\n",
              "                (cv1): RepConv(\n",
              "                  (act): SiLU(inplace=True)\n",
              "                  (conv1): Conv(\n",
              "                    (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                  (conv2): Conv(\n",
              "                    (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                    (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                    (act): Identity()\n",
              "                  )\n",
              "                )\n",
              "                (cv2): Conv(\n",
              "                  (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "                  (act): SiLU(inplace=True)\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (1): Conv(\n",
              "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (cv4): Conv(\n",
              "          (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "          (act): SiLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "      (22): Segment(\n",
              "        (cv2): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Conv(\n",
              "              (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (1-2): 2 x Sequential(\n",
              "            (0): Conv(\n",
              "              (conv): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (cv3): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Conv(\n",
              "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv(\n",
              "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (1-2): 2 x Sequential(\n",
              "            (0): Conv(\n",
              "              (conv): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv(\n",
              "              (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "        (dfl): DFL(\n",
              "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        )\n",
              "        (proto): Proto(\n",
              "          (cv1): Conv(\n",
              "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (upsample): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
              "          (cv2): Conv(\n",
              "            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (cv3): Conv(\n",
              "            (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "        )\n",
              "        (cv4): ModuleList(\n",
              "          (0): Sequential(\n",
              "            (0): Conv(\n",
              "              (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "          (1-2): 2 x Sequential(\n",
              "            (0): Conv(\n",
              "              (conv): Conv2d(512, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (1): Conv(\n",
              "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
              "              (act): SiLU(inplace=True)\n",
              "            )\n",
              "            (2): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Build a YOLOv9c model from pretrained weight\n",
        "model = YOLO(\"yolov9c-seg.pt\")\n",
        "tracker = sv.ByteTrack()\n",
        "\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "id": "2oVq68y3BQy6",
        "outputId": "0907304e-cdb4-42c3-9a18-4665ba92bf97"
      },
      "outputs": [],
      "source": [
        "\n",
        "def calculate_head_and_leg_points(polygon_points, threshold=0.12):\n",
        "    \"\"\"\n",
        "    Calculate the average points for the head and leg based on the top and bottom threshold percentage of Y-coordinates.\n",
        "\n",
        "    Parameters:\n",
        "    polygon_points (np.array): The polygon points.\n",
        "    threshold (float): The percentage to consider for the top and bottom points (default is 0.07).\n",
        "\n",
        "    Returns:\n",
        "    tuple: The average points for the head and leg.\n",
        "    \"\"\"\n",
        "    poly = np.array(polygon_points, dtype=np.int32)\n",
        "\n",
        "    # Extract Y-coordinates\n",
        "    y_coords = poly[:, 1]\n",
        "\n",
        "    # Calculate top and bottom threshold percentage\n",
        "    top_threshold_indices = np.argsort(y_coords)[:max(int(threshold * len(y_coords)), 1)]\n",
        "    bottom_threshold_indices = np.argsort(y_coords)[- max (int(threshold * len(y_coords)), 1):]\n",
        "\n",
        "    # Get average points for head and leg\n",
        "    head_points = poly[top_threshold_indices]\n",
        "    leg_points = poly[bottom_threshold_indices]\n",
        "\n",
        "    head_avg = np.mean(head_points, axis=0).astype(int)\n",
        "    leg_avg = np.mean(leg_points, axis=0).astype(int)\n",
        "\n",
        "    leg_avg[1] = np.max(y_coords)\n",
        "    head_avg[1] = np.min(y_coords)\n",
        "\n",
        "\n",
        "    return head_avg, leg_avg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0sEUI3aUHWIK"
      },
      "outputs": [],
      "source": [
        "def process_detection_results(model, frame):\n",
        "    # Convert frame to RGB\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    # Perform inference using the model\n",
        "    results = model(frame_rgb, classes=[0], conf=0.45)[0]\n",
        "    masks = results.masks\n",
        "    boxes = results.boxes\n",
        "\n",
        "    # Dictionary to store head and leg positions\n",
        "    legs_and_heads = {}\n",
        "\n",
        "    # List to store bounding boxes\n",
        "    boxes_list = []\n",
        "\n",
        "    # Iterate over each detected box and mask\n",
        "    for idx, box in enumerate(boxes):\n",
        "        # Convert box coordinates to list\n",
        "        xyxy = box.cpu().xyxy.tolist()[0]\n",
        "        boxes_list.append(xyxy)\n",
        "\n",
        "        # Calculate head and leg positions for the current mask\n",
        "        head_pos, leg_pos = calculate_head_and_leg_points(masks[idx].xy[0])\n",
        "        legs_and_heads[idx] = (head_pos, leg_pos)\n",
        "\n",
        "    return results, legs_and_heads, boxes_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_IOU( bbox1, bbox2):\n",
        "      \"\"\"\n",
        "      Calculate the Intersection over Union (IoU) between two bounding boxes.\n",
        "\n",
        "      Args:\n",
        "      - bbox1: Coordinates of the first bounding box in the format [x1, y1, x2, y2].\n",
        "      - bbox2: Coordinates of the second bounding box in the format [x1, y1, x2, y2].\n",
        "\n",
        "      Returns:\n",
        "      - iou: Intersection over Union (IoU) score between the two bounding boxes.\n",
        "      \"\"\"\n",
        "\n",
        "      x1, y1, x2, y2 = bbox1\n",
        "      X1, Y1, X2, Y2 = bbox2\n",
        "\n",
        "      # Calculate intersection area\n",
        "      interArea = max(0, min(x2, X2) - max(x1, X1)) * max(0, min(y2, Y2) - max(y1, Y1))\n",
        "\n",
        "      # Calculate areas of bounding boxes\n",
        "      bbox1_area = (x2 - x1) * (y2 - y1)\n",
        "      bbox2_area = (X2 - X1) * (Y2 - Y1)\n",
        "\n",
        "      # Calculate IoU\n",
        "      iou = interArea / (bbox1_area + bbox2_area - interArea)\n",
        "\n",
        "      return iou"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def match(xyxy, boxes):\n",
        "    best_idx = 0\n",
        "    best_iou = 0.0\n",
        "\n",
        "    for idx, box in enumerate(boxes):\n",
        "        iou = get_IOU(box, xyxy)\n",
        "\n",
        "        if iou>best_iou:\n",
        "            best_iou = iou\n",
        "            best_idx = idx\n",
        "\n",
        "    return best_idx\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Depth estimation model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "def load_depth_model(device, encoder='vitl', load_from='depth/assets/depth_anything_v2_metric_vkitti_vitl.pth', max_depth=25):\n",
        "    \n",
        "    model_configs = {\n",
        "        'vits': {'encoder': 'vits', 'features': 64, 'out_channels': [48, 96, 192, 384]},\n",
        "        'vitb': {'encoder': 'vitb', 'features': 128, 'out_channels': [96, 192, 384, 768]},\n",
        "        'vitl': {'encoder': 'vitl', 'features': 256, 'out_channels': [256, 512, 1024, 1024]},\n",
        "        'vitg': {'encoder': 'vitg', 'features': 384, 'out_channels': [1536, 1536, 1536, 1536]}\n",
        "    }\n",
        "    \n",
        "    depth_anything = DepthAnythingV2(**{**model_configs[encoder], 'max_depth': max_depth})\n",
        "    depth_anything.load_state_dict(torch.load(load_from, map_location=device))\n",
        "    depth_anything = depth_anything.to(device).eval()\n",
        "    \n",
        "    return depth_anything"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "depth_anything= load_depth_model(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Camera calibration on the first frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "from CameraCalibrateApp import CameraCalibrateApp\n",
        "\n",
        "app = CameraCalibrateApp(VIDEO_PATH)\n",
        "line_data, frame = app.start()\n",
        "\n",
        "depth_map = depth_anything.infer_image(frame)\n",
        "\n",
        "\n",
        "anchors = []\n",
        "\n",
        "for start, end, true_length in line_data:\n",
        "    length_pixels = np.sqrt((end[0] - start[0]) ** 2 + (end[1] - start[1]) ** 2)\n",
        "    middle_point = ((start[0] + end[0]) // 2, (start[1] + end[1]) // 2)\n",
        "    depth = depth_map[middle_point[1], middle_point[0]]\n",
        "\n",
        "    length_ratio = (length_pixels * np.sqrt (depth) )/ true_length\n",
        "    \n",
        "    anchors.append((length_pixels,  true_length,  depth))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Dataset and model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 384x640 9 persons, 202.4ms\n",
            "Speed: 3.5ms preprocess, 202.4ms inference, 469.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 0\n",
            "\n",
            "0: 384x640 12 persons, 19.9ms\n",
            "Speed: 2.1ms preprocess, 19.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 90\n",
            "\n",
            "0: 384x640 15 persons, 20.3ms\n",
            "Speed: 2.5ms preprocess, 20.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 180\n",
            "\n",
            "0: 384x640 15 persons, 21.6ms\n",
            "Speed: 2.2ms preprocess, 21.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 270\n",
            "\n",
            "0: 384x640 17 persons, 21.1ms\n",
            "Speed: 2.5ms preprocess, 21.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 360\n",
            "\n",
            "0: 384x640 12 persons, 19.1ms\n",
            "Speed: 1.9ms preprocess, 19.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 450\n",
            "\n",
            "0: 384x640 14 persons, 21.4ms\n",
            "Speed: 2.0ms preprocess, 21.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 540\n",
            "\n",
            "0: 384x640 13 persons, 20.2ms\n",
            "Speed: 2.2ms preprocess, 20.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 630\n",
            "\n",
            "0: 384x640 10 persons, 20.6ms\n",
            "Speed: 2.1ms preprocess, 20.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 720\n",
            "\n",
            "0: 384x640 14 persons, 20.6ms\n",
            "Speed: 2.7ms preprocess, 20.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 810\n",
            "\n",
            "0: 384x640 15 persons, 21.4ms\n",
            "Speed: 2.1ms preprocess, 21.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 900\n",
            "\n",
            "0: 384x640 14 persons, 23.2ms\n",
            "Speed: 2.5ms preprocess, 23.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 990\n",
            "\n",
            "0: 384x640 10 persons, 21.3ms\n",
            "Speed: 2.0ms preprocess, 21.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 1080\n",
            "\n",
            "0: 384x640 14 persons, 20.9ms\n",
            "Speed: 2.0ms preprocess, 20.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 1170\n",
            "\n",
            "0: 384x640 14 persons, 22.0ms\n",
            "Speed: 2.3ms preprocess, 22.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 1260\n",
            "\n",
            "0: 384x640 11 persons, 21.9ms\n",
            "Speed: 2.0ms preprocess, 21.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 1350\n",
            "\n",
            "0: 384x640 10 persons, 20.0ms\n",
            "Speed: 1.9ms preprocess, 20.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 1440\n",
            "\n",
            "0: 384x640 12 persons, 21.2ms\n",
            "Speed: 2.8ms preprocess, 21.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 1530\n",
            "\n",
            "0: 384x640 9 persons, 21.2ms\n",
            "Speed: 1.9ms preprocess, 21.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 1620\n",
            "\n",
            "0: 384x640 11 persons, 22.5ms\n",
            "Speed: 3.3ms preprocess, 22.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 1710\n",
            "\n",
            "0: 384x640 12 persons, 20.2ms\n",
            "Speed: 2.8ms preprocess, 20.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 1800\n",
            "\n",
            "0: 384x640 10 persons, 19.2ms\n",
            "Speed: 2.6ms preprocess, 19.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 1890\n",
            "\n",
            "0: 384x640 13 persons, 20.7ms\n",
            "Speed: 2.1ms preprocess, 20.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 1980\n",
            "\n",
            "0: 384x640 9 persons, 20.1ms\n",
            "Speed: 2.0ms preprocess, 20.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 2070\n",
            "\n",
            "0: 384x640 10 persons, 20.4ms\n",
            "Speed: 2.2ms preprocess, 20.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 2160\n",
            "\n",
            "0: 384x640 14 persons, 21.2ms\n",
            "Speed: 2.6ms preprocess, 21.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 2250\n",
            "\n",
            "0: 384x640 12 persons, 20.4ms\n",
            "Speed: 2.6ms preprocess, 20.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 2340\n",
            "\n",
            "0: 384x640 15 persons, 23.0ms\n",
            "Speed: 2.1ms preprocess, 23.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 2430\n",
            "\n",
            "0: 384x640 12 persons, 22.2ms\n",
            "Speed: 2.0ms preprocess, 22.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 2520\n",
            "\n",
            "0: 384x640 11 persons, 22.2ms\n",
            "Speed: 2.3ms preprocess, 22.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 2610\n",
            "\n",
            "0: 384x640 12 persons, 20.8ms\n",
            "Speed: 2.9ms preprocess, 20.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 2700\n",
            "\n",
            "0: 384x640 10 persons, 21.3ms\n",
            "Speed: 1.8ms preprocess, 21.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 2790\n",
            "\n",
            "0: 384x640 8 persons, 21.3ms\n",
            "Speed: 1.8ms preprocess, 21.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 2880\n",
            "\n",
            "0: 384x640 11 persons, 21.3ms\n",
            "Speed: 2.1ms preprocess, 21.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 2970\n",
            "\n",
            "0: 384x640 11 persons, 20.8ms\n",
            "Speed: 2.7ms preprocess, 20.8ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 3060\n",
            "\n",
            "0: 384x640 8 persons, 19.1ms\n",
            "Speed: 1.8ms preprocess, 19.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 3150\n",
            "\n",
            "0: 384x640 7 persons, 20.0ms\n",
            "Speed: 2.6ms preprocess, 20.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 3240\n",
            "\n",
            "0: 384x640 9 persons, 22.6ms\n",
            "Speed: 2.0ms preprocess, 22.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 3330\n",
            "\n",
            "0: 384x640 11 persons, 21.9ms\n",
            "Speed: 2.3ms preprocess, 21.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 3420\n",
            "{1: [(4.339463, 492.7961038807024), (5.9638095, 321.0763149159402), (7.46262, 237.8423847845459), (8.946747, 180.02499826412998), (12.485447, 81.2219182240853)], 2: [(4.293929, 477.55418540726873), (6.0730863, 324.18667461818967), (7.5012712, 237.47420912595962), (8.560999, 198.00252523642217), (10.03565, 147.05441169852742)], 3: [(6.3678226, 372.5922704512266), (5.364261, 411.0012165432117), (4.9061136, 457.0525133942488), (6.889876, 309.04045042680093), (4.177382, 438.0182644593716), (4.599247, 358.1759344232943), (4.4782624, 450.75048530201275), (2.8496294, 789.0101393518337), (4.566023, 414.004830889689), (3.8647432, 428.5907138518052)], 4: [(4.6307726, 489.0092023673992), (3.8763902, 540.3702434442519), (3.6898718, 582.7726829562278), (3.6239264, 540.4535132645545), (4.096687, 423.38280550820673), (5.3001595, 396.42527669158534), (7.684198, 234.10467744152402), (8.364919, 153.11760186209813), (8.891727, 165.04847772699995)], 5: [(7.0588927, 273.045783706689), (7.8398767, 249.20072231034965), (5.531239, 285.63263118908526), (3.6192374, 573.0008725996846), (4.423365, 501.063868184486), (6.0567565, 198.16155025635018), (5.5279155, 198.6454127333425), (9.414576, 150.74813431681335), (6.3187847, 189.04232330353963), (6.58163, 225.03555274667156), (7.46503, 186.21761463406193)], 6: [(2.0173116, 476.4241807465276), (4.402277, 555.2602993191572), (6.1405334, 310.17736861350795), (7.0897307, 273.1483113621609)], 7: [(2.8706782, 870.0367808317071), (2.3652465, 969.1011299136948), (2.4436374, 921.1063999343398), (3.9291914, 489.800979990853), (6.4018855, 345.00144927231827), (5.3615127, 345.7658167025769), (5.942615, 273.1483113621609), (4.768535, 441.11336411403363), (4.1954074, 555.1297145712883), (4.864888, 423.0425510513097), (4.2202477, 501.36613367877175), (4.0260234, 630.8121748983607), (2.5857925, 468.0267086395818), (3.221733, 716.601004743923), (3.853822, 558.108412407482), (5.4407125, 423.14300183271376), (4.6732135, 429.00116549958227), (4.1896296, 456.03947197583676), (3.4882593, 498.169649818212), (2.6219862, 594.2432162002357)], 8: [(5.928516, 300.0266654815868), (4.6773367, 465.02688094345683), (7.972106, 240.10206163213175), (7.7002525, 285.08595195133694), (5.729403, 221.35943621178654), (8.362146, 192.09372712298546), (7.335864, 286.37213551601), (7.052018, 273.1483113621609), (7.8315067, 240.00833318866242), (8.384966, 156.11534197509224), (4.9272914, 190.05525512334563), (8.143969, 168.1903683330291), (8.139815, 200.4120754844877)], 9: [(7.3516417, 201.08953229842672), (6.6068335, 324.1249758966439), (4.443553, 381.1062843879644), (4.843199, 390.1281840626232), (4.9426904, 445.7095466781029), (5.284866, 355.0281678965769), (4.632335, 472.49232798004243), (4.3133764, 450.05444115129006), (4.591787, 390.8657058376956), (7.9715185, 264.09278672466615), (6.9906, 264.12118430750684), (7.107572, 262.1011255221923), (6.3413796, 285.56785533389433), (5.640095, 312.00160255998685), (4.4379296, 427.6037885706814)], 11: [(5.418859, 345.9783230203881), (5.720071, 381.52457325839447), (7.2994256, 241.29857024027308), (5.0692954, 345.5792239125495), (3.691849, 612.0816938938789), (3.811805, 516.0155036430591), (2.2582135, 1069.052851827261), (2.747109, 888.0), (4.0276785, 517.2542894940553), (5.3903265, 381.02099679676445), (7.0782557, 261.1225765804252), (6.600394, 273.045783706689), (8.858477, 258.00775182152955), (5.0940857, 355.44338508403837), (3.6228442, 528.21302520858), (3.950841, 477.6546869863207)], 12: [(6.676366, 336.0238086802779), (7.3288264, 255.15877409957903), (6.9758954, 240.25195108468944), (8.122989, 249.12848090894786), (5.518978, 357.03501228871096), (8.183537, 213.11499243366245), (8.495186, 202.09403751719148), (6.083918, 285.25251970841555), (4.8246136, 417.0107912272775), (7.7762065, 237.00210969525145), (8.096858, 201.89601283829256), (6.5717974, 261.04788832702707), (8.448197, 238.01890681204299), (8.09318, 237.17082451262846), (7.5960827, 238.3149177034455), (7.8673034, 238.53301658261063), (5.0067163, 408.09925263347395), (3.575811, 543.1804488381371)], 13: [(7.3254504, 237.00843866833097), (8.609324, 177.18069872308325), (10.335222, 151.6047492659778), (9.25858, 189.0952141118331), (11.488534, 102.12247548899312), (12.943293, 94.2019108086455)], 10: [(3.0951343, 838.3185552044043), (3.23845, 872.7319176012758), (5.0902457, 516.1172347442003), (5.1263013, 357.4045327076868), (6.1407413, 297.1683024819437), (7.105506, 252.23996511258878), (7.81569, 257.12642804659345), (3.4701116, 550.5288366652559)], 22: [(6.7862306, 310.75713990188547), (7.718842, 283.9242856819402), (6.1689787, 312.23068395018447), (4.087118, 198.022725968511), (3.5182045, 468.00961528584), (4.7152367, 297.1363323459452), (4.816633, 315.02539580167183), (4.5951037, 414.0), (4.547771, 246.81166909204273), (4.4796343, 414.01086942253096), (3.9451478, 345.03622998172233), (2.7733593, 582.3787427439295), (2.3104804, 570.042980835656)], 23: [(7.673512, 252.03174403237384), (9.000864, 186.26862323000083), (7.9724474, 210.08569680013915), (8.432922, 168.1903683330291), (8.728077, 168.07438829280326), (7.1630244, 225.00888871331284), (6.4666853, 345.11737133908514), (5.6589537, 315.35694062442957), (4.390187, 523.1720558286729), (3.5650117, 609.099335084188)], 29: [(7.6236134, 216.0092590608097), (6.868046, 258.0484450641003), (4.7503633, 381.03280698648507), (5.2198887, 321.1261434389919), (3.7878559, 522.0153254455275), (4.5857015, 441.0918271743425), (3.953139, 482.0124479720415), (3.5918412, 645.3417699173051), (5.705174, 297.0269348055829), (5.461561, 357.2744043448957)], 42: [(3.5368667, 588.1436899261948), (3.7971327, 606.1616945997165), (4.521181, 471.51352048483193), (4.344203, 510.0156860332827), (3.5218186, 662.6318736674233), (2.5376458, 724.5419242528344)], 50: [(4.4931808, 435.1654857637494), (5.7973557, 297.0), (5.5647798, 402.0012437791704), (5.9406176, 263.47106102948004), (4.8608403, 378.0052909682614), (6.2790174, 309.13104017552166), (4.450363, 502.22405358564816), (5.071663, 453.13353440238785), (4.1602726, 478.07217028394365), (2.9056478, 667.200119904066), (4.3288383, 400.2249367543207), (5.561966, 333.00600595184466), (5.7632227, 261.0689564080724), (4.257345, 466.5501044903966), (2.3338141, 546.0329660377658), (3.668741, 453.00993366591865), (2.0571234, 781.74484328328), (2.5477014, 618.0072815105013)], 51: [(4.760878, 201.12185361118767), (5.2711635, 207.00966161027364), (5.570597, 99.72462083156798), (7.572501, 240.25195108468944), (10.770315, 153.0), (12.903968, 78.05767098754612)], 58: [(2.543919, 798.0400992431395), (3.1508212, 710.6229661360517), (2.5693185, 1021.4274325667976), (2.7170403, 822.5843421801803), (3.5362232, 200.4120754844877)], 62: [(8.320446, 195.31000998412753), (6.983157, 237.05273674859777), (3.3095925, 336.0238086802779), (4.2285028, 438.092455995307), (5.8598137, 312.01442274356486), (6.0475287, 286.90416518412553), (5.7810135, 285.56785533389433), (5.631346, 285.63263118908526), (5.4105573, 285.56785533389433)], 61: [(5.225758, 177.55280904564702), (7.9623218, 177.0706073858674), (8.345605, 159.0)], 68: [(8.419086, 144.4195277654653), (8.90495, 174.0258601472781), (8.1010685, 189.01058171435798), (10.158867, 117.06835610018618), (10.701261, 117.00427342623003), (10.97462, 117.01709276853532)], 82: [(8.54119, 189.06612599828665), (5.5415363, 360.3553801457667), (2.777181, 798.1409649930267), (2.447308, 1050.400399847601), (2.344817, 954.0005241088708)], 90: [(7.64497, 261.00766272276377), (4.876286, 381.15875957401266), (3.1331263, 513.2192513926187), (7.065307, 273.1483113621609), (7.233007, 273.22152184628504), (6.826461, 261.15512631384433)], 100: [(13.880386, 90.0499861188218)], 106: [(2.2778258, 1017.0044247691354), (2.6709487, 456.0899034181748), (3.3923252, 466.71725916233265), (2.779944, 690.0007246373007)], 118: [(4.075449, 465.4299087940095), (5.6011386, 348.0703951789063), (4.741429, 321.05606986942325), (5.2641277, 238.64827675891564), (5.6580596, 339.6498196672567), (3.1421242, 465.0526851873882)], 121: [(6.127126, 213.03755537463343), (7.703094, 201.20139164528658), (6.3773274, 273.3587386567329)], 128: [(7.2253084, 261.0689564080724)], 130: [(11.653269, 129.0), (11.403564, 129.0620006043607), (10.97241, 126.14277624977183)], 136: [(8.135058, 201.2486024796197), (8.109333, 203.85534086699815), (8.049858, 198.6454127333425), (10.687857, 141.01418368376991), (10.053256, 150.02999700059985)], 135: [(11.306011, 117.03845521878696), (9.717391, 201.06217943710845)], 134: [(11.182648, 106.06601717798213), (11.031574, 117.61377470347595), (10.61874, 153.20900756809309)], 155: [(20.002226, 69.06518659932803), (17.972687, 81.2219182240853)], 169: [(11.26273, 162.30834852218786), (11.734886, 77.88452991448301), (13.344543, 120.01666550941998), (14.757287, 117.957619508025)], 177: [(10.127604, 177.18069872308325), (10.230046, 153.16004700965587)], 181: [(7.5253563, 225.00888871331284)]}\n"
          ]
        }
      ],
      "source": [
        "cap = cv2.VideoCapture(VIDEO_PATH)\n",
        "\n",
        "dic = {}\n",
        "frame_count = -1\n",
        "\n",
        "step = 90\n",
        "frames_limit = 6000\n",
        "\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    frame_count += 1\n",
        "    if not ret:\n",
        "        break\n",
        "    \n",
        "    if frame_count % step != 0:\n",
        "         continue\n",
        "    results, legs_and_heads, boxes = process_detection_results(model, frame)\n",
        "\n",
        "    detections = sv.Detections.from_ultralytics(results)\n",
        "    detections = tracker.update_with_detections(detections)\n",
        "\n",
        "    depth_map = depth_anything.infer_image(frame)\n",
        "\n",
        "\n",
        "    for detection_idx, _ in enumerate(detections):\n",
        "            xyxy = detections[detection_idx].xyxy.tolist()[0]\n",
        "            obj_id = detections[detection_idx].tracker_id[0]\n",
        "\n",
        "            best_idx = match(xyxy, boxes)\n",
        "\n",
        "\n",
        "            head_pos, leg_pos = legs_and_heads[best_idx]\n",
        "\n",
        "            #####\n",
        "            start, end = head_pos, leg_pos\n",
        "            length_pixels = np.sqrt((end[0] - start[0]) ** 2 + (end[1] - start[1]) ** 2)\n",
        "            middle_point = ((start[0] + end[0]) // 2, (start[1] + end[1]) // 2)\n",
        "\n",
        "            depth = depth_map[middle_point[1], middle_point[0]]\n",
        "\n",
        "            if obj_id not in dic:\n",
        "                 dic[obj_id] = [(depth, length_pixels)]\n",
        "            else: \n",
        "                dic[obj_id].append((depth, length_pixels)) \n",
        "\n",
        "    \n",
        "    cv2.waitKey(1) \n",
        "\n",
        "    \n",
        "    if frame_count >= frames_limit:\n",
        "        break\n",
        "    print(f\"Processed frame {frame_count}\")\n",
        "\n",
        "# Release everything when finished\n",
        "cap.release()\n",
        "\n",
        "cv2.destroyAllWindows()\n",
        "print(dic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to get the data element\n",
        "def get_data_element(p1, p2):\n",
        "    depth_diff = p2[0] - p1[0]\n",
        "    \n",
        "    if depth_diff == 0:\n",
        "        return None\n",
        "    \n",
        "    return p1[0], depth_diff, p2[1]/p1[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2680\n"
          ]
        }
      ],
      "source": [
        "# Generate dataset using permutations\n",
        "dataset = []\n",
        "for id_data in dic.values():\n",
        "    # Generate permutations of two elements\n",
        "    permutations = list(itertools.permutations(id_data, 2))\n",
        "    for perm in permutations:\n",
        "        p1, p2 = perm\n",
        "        scale_change = get_data_element(p1, p2)\n",
        "        if scale_change is not None:\n",
        "            dataset.append(scale_change)\n",
        "print(len(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10, Loss: 0.08349927514791489\n",
            "Epoch 2/10, Loss: 0.08998268842697144\n",
            "Epoch 3/10, Loss: 0.06479211896657944\n",
            "Epoch 4/10, Loss: 0.07979784905910492\n",
            "Epoch 5/10, Loss: 0.03559689596295357\n",
            "Epoch 6/10, Loss: 0.10715124011039734\n",
            "Epoch 7/10, Loss: 0.08736579865217209\n",
            "Epoch 8/10, Loss: 0.12562216818332672\n",
            "Epoch 9/10, Loss: 0.05495157837867737\n",
            "Epoch 10/10, Loss: 0.0324413925409317\n",
            "Test Loss: 0.05209240152993623\n"
          ]
        }
      ],
      "source": [
        "# Prepare data\n",
        "X = [[elem[0], elem[1]] for elem in dataset]\n",
        "y = [elem[2] for elem in dataset]\n",
        "\n",
        "X = torch.tensor(X, dtype=torch.float32)\n",
        "y = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# Create a dataset and split into training and test sets\n",
        "full_dataset = TensorDataset(X, y)\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "test_size = len(full_dataset) - train_size\n",
        "train_dataset, test_dataset = random_split(full_dataset, [train_size, test_size])\n",
        "\n",
        "# Data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Define the neural network model\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(2, 64)\n",
        "        self.fc2 = nn.Linear(64, 128)\n",
        "        self.fc25 = nn.Linear(128, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "        self.fc4 = nn.Linear(64, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc25(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "def custom_loss(y_pred, y_true, epsilon=1e-3):\n",
        "    y_true = torch.clamp(y_true, min=epsilon)  # Ensure y_true is not zero\n",
        "    l = torch.mean(    (torch.log(y_pred) - torch.log(y_true))*      (torch.log(y_pred) - torch.log(y_true))  )\n",
        "    \n",
        "\n",
        "    return l\n",
        "\n",
        "\n",
        "# Initialize the model, loss function, and optimizer\n",
        "cam_clib_model = SimpleNN()\n",
        "optimizer = optim.Adam(cam_clib_model.parameters(), lr=0.001)\n",
        "\n",
        "# Training the cam_clib_model\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    cam_clib_model.train()\n",
        "    for X_batch, y_batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = cam_clib_model(X_batch)\n",
        "        loss = custom_loss(y_pred, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 1 == 0:\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
        "\n",
        "# Evaluate the cam_clib_model\n",
        "cam_clib_model.eval()\n",
        "test_loss = 0.0\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        y_pred = cam_clib_model(X_batch)\n",
        "        loss = custom_loss(y_pred, y_batch)\n",
        "        test_loss += loss.item()\n",
        "\n",
        "test_loss /= len(test_loader)\n",
        "print(f'Test Loss: {test_loss}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3.4697468280792236"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def infer_cam_calib(cam_clib_model, current_depth, depth_diff):\n",
        "    current_depth = float(current_depth)\n",
        "    depth_diff = float(depth_diff)\n",
        "    scale_change = cam_clib_model(torch.tensor([current_depth, depth_diff], dtype=torch.float32))\n",
        "    return scale_change.item()\n",
        "infer_cam_calib(cam_clib_model, 4, -5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def annotate_frame(frame, head_pos, leg_pos, obj_id):          \n",
        "    # Draw circles or markers for head and leg positions\n",
        "    cv2.circle(frame, head_pos, 5, (0, 255, 0), -1)  # Green circle for head\n",
        "    cv2.circle(frame, leg_pos, 5, (0, 0, 255), -1)   # Red circle for leg\n",
        "    cv2.line(frame, head_pos, leg_pos, (255, 0, 0), 2) \n",
        "    \n",
        "    # Draw the id in the center point of the head and the leg\n",
        "    midpoint = ((head_pos[0] + leg_pos[0]) // 2, (head_pos[1] + leg_pos[1]) // 2)\n",
        "    cv2.putText(frame, str(obj_id), midpoint, cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
        "\n",
        "    return frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "def estimate_hight(c_length_pixels, c_depth, anchors):\n",
        "    n = len(anchors)\n",
        "\n",
        "    av_c_tall = 0.0\n",
        "\n",
        "    for a_length_pixels,  a_true_length,  a_depth in anchors:\n",
        "        c_tranformed_length_pixels = infer_cam_calib(cam_clib_model, c_depth, a_depth - c_depth) * c_length_pixels\n",
        "        c_tall = a_true_length * ( c_tranformed_length_pixels / a_length_pixels   )\n",
        "\n",
        "        av_c_tall += c_tall/n\n",
        "\n",
        "    return av_c_tall      \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 384x640 9 persons, 29.5ms\n",
            "Speed: 13.3ms preprocess, 29.5ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 1/3493\n",
            "\n",
            "0: 384x640 9 persons, 22.2ms\n",
            "Speed: 2.0ms preprocess, 22.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 2/3493\n",
            "\n",
            "0: 384x640 9 persons, 21.3ms\n",
            "Speed: 2.2ms preprocess, 21.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 3/3493\n",
            "\n",
            "0: 384x640 10 persons, 22.1ms\n",
            "Speed: 2.5ms preprocess, 22.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 4/3493\n",
            "\n",
            "0: 384x640 10 persons, 22.1ms\n",
            "Speed: 2.2ms preprocess, 22.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 5/3493\n",
            "\n",
            "0: 384x640 10 persons, 19.8ms\n",
            "Speed: 1.8ms preprocess, 19.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 6/3493\n",
            "\n",
            "0: 384x640 10 persons, 20.8ms\n",
            "Speed: 1.9ms preprocess, 20.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 7/3493\n",
            "\n",
            "0: 384x640 10 persons, 19.7ms\n",
            "Speed: 1.9ms preprocess, 19.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 8/3493\n",
            "\n",
            "0: 384x640 10 persons, 21.5ms\n",
            "Speed: 2.0ms preprocess, 21.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 9/3493\n",
            "\n",
            "0: 384x640 10 persons, 20.2ms\n",
            "Speed: 2.0ms preprocess, 20.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 10/3493\n",
            "\n",
            "0: 384x640 10 persons, 22.1ms\n",
            "Speed: 1.9ms preprocess, 22.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 11/3493\n",
            "\n",
            "0: 384x640 10 persons, 20.6ms\n",
            "Speed: 1.8ms preprocess, 20.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 12/3493\n",
            "\n",
            "0: 384x640 10 persons, 20.9ms\n",
            "Speed: 2.0ms preprocess, 20.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 13/3493\n",
            "\n",
            "0: 384x640 10 persons, 19.9ms\n",
            "Speed: 1.8ms preprocess, 19.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 14/3493\n",
            "\n",
            "0: 384x640 9 persons, 20.4ms\n",
            "Speed: 2.3ms preprocess, 20.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 15/3493\n",
            "\n",
            "0: 384x640 11 persons, 21.6ms\n",
            "Speed: 2.1ms preprocess, 21.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 16/3493\n",
            "\n",
            "0: 384x640 9 persons, 21.1ms\n",
            "Speed: 2.0ms preprocess, 21.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 17/3493\n",
            "\n",
            "0: 384x640 10 persons, 19.4ms\n",
            "Speed: 2.0ms preprocess, 19.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 18/3493\n",
            "\n",
            "0: 384x640 10 persons, 21.5ms\n",
            "Speed: 1.9ms preprocess, 21.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 19/3493\n",
            "\n",
            "0: 384x640 11 persons, 18.9ms\n",
            "Speed: 1.8ms preprocess, 18.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 20/3493\n",
            "\n",
            "0: 384x640 11 persons, 21.1ms\n",
            "Speed: 2.6ms preprocess, 21.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 21/3493\n",
            "\n",
            "0: 384x640 12 persons, 20.7ms\n",
            "Speed: 2.6ms preprocess, 20.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 22/3493\n",
            "\n",
            "0: 384x640 13 persons, 22.4ms\n",
            "Speed: 1.9ms preprocess, 22.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 23/3493\n",
            "\n",
            "0: 384x640 12 persons, 19.5ms\n",
            "Speed: 1.8ms preprocess, 19.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 24/3493\n",
            "\n",
            "0: 384x640 12 persons, 19.7ms\n",
            "Speed: 1.8ms preprocess, 19.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 25/3493\n",
            "\n",
            "0: 384x640 11 persons, 20.2ms\n",
            "Speed: 2.0ms preprocess, 20.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 26/3493\n",
            "\n",
            "0: 384x640 11 persons, 20.5ms\n",
            "Speed: 2.2ms preprocess, 20.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 27/3493\n",
            "\n",
            "0: 384x640 12 persons, 21.3ms\n",
            "Speed: 2.2ms preprocess, 21.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 28/3493\n",
            "\n",
            "0: 384x640 12 persons, 20.5ms\n",
            "Speed: 2.1ms preprocess, 20.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 29/3493\n",
            "\n",
            "0: 384x640 11 persons, 21.6ms\n",
            "Speed: 2.6ms preprocess, 21.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 30/3493\n",
            "\n",
            "0: 384x640 13 persons, 19.0ms\n",
            "Speed: 2.0ms preprocess, 19.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 31/3493\n",
            "\n",
            "0: 384x640 12 persons, 19.7ms\n",
            "Speed: 1.8ms preprocess, 19.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 32/3493\n",
            "\n",
            "0: 384x640 11 persons, 21.1ms\n",
            "Speed: 2.2ms preprocess, 21.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 33/3493\n",
            "\n",
            "0: 384x640 11 persons, 18.9ms\n",
            "Speed: 1.9ms preprocess, 18.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 34/3493\n",
            "\n",
            "0: 384x640 12 persons, 20.2ms\n",
            "Speed: 1.9ms preprocess, 20.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 35/3493\n",
            "\n",
            "0: 384x640 11 persons, 19.5ms\n",
            "Speed: 1.9ms preprocess, 19.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 36/3493\n",
            "\n",
            "0: 384x640 11 persons, 20.8ms\n",
            "Speed: 2.0ms preprocess, 20.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 37/3493\n",
            "\n",
            "0: 384x640 11 persons, 20.5ms\n",
            "Speed: 2.0ms preprocess, 20.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 38/3493\n",
            "\n",
            "0: 384x640 11 persons, 20.1ms\n",
            "Speed: 1.9ms preprocess, 20.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 39/3493\n",
            "\n",
            "0: 384x640 11 persons, 21.5ms\n",
            "Speed: 2.5ms preprocess, 21.5ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 40/3493\n",
            "\n",
            "0: 384x640 11 persons, 18.9ms\n",
            "Speed: 2.0ms preprocess, 18.9ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 41/3493\n",
            "\n",
            "0: 384x640 12 persons, 19.7ms\n",
            "Speed: 2.2ms preprocess, 19.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 42/3493\n",
            "\n",
            "0: 384x640 11 persons, 20.6ms\n",
            "Speed: 2.2ms preprocess, 20.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 43/3493\n",
            "\n",
            "0: 384x640 12 persons, 20.6ms\n",
            "Speed: 2.6ms preprocess, 20.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 44/3493\n",
            "\n",
            "0: 384x640 10 persons, 19.1ms\n",
            "Speed: 1.8ms preprocess, 19.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 45/3493\n",
            "\n",
            "0: 384x640 11 persons, 20.1ms\n",
            "Speed: 2.2ms preprocess, 20.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 46/3493\n",
            "\n",
            "0: 384x640 11 persons, 19.4ms\n",
            "Speed: 1.9ms preprocess, 19.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 47/3493\n",
            "\n",
            "0: 384x640 11 persons, 21.8ms\n",
            "Speed: 2.6ms preprocess, 21.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 48/3493\n",
            "\n",
            "0: 384x640 10 persons, 21.0ms\n",
            "Speed: 2.0ms preprocess, 21.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 49/3493\n",
            "\n",
            "0: 384x640 10 persons, 20.6ms\n",
            "Speed: 2.3ms preprocess, 20.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 50/3493\n",
            "\n",
            "0: 384x640 10 persons, 20.9ms\n",
            "Speed: 1.9ms preprocess, 20.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 51/3493\n",
            "\n",
            "0: 384x640 10 persons, 20.2ms\n",
            "Speed: 2.2ms preprocess, 20.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 52/3493\n",
            "\n",
            "0: 384x640 10 persons, 21.0ms\n",
            "Speed: 2.1ms preprocess, 21.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 53/3493\n",
            "\n",
            "0: 384x640 12 persons, 19.6ms\n",
            "Speed: 1.8ms preprocess, 19.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 54/3493\n",
            "\n",
            "0: 384x640 12 persons, 19.3ms\n",
            "Speed: 1.9ms preprocess, 19.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 55/3493\n",
            "\n",
            "0: 384x640 11 persons, 20.0ms\n",
            "Speed: 1.9ms preprocess, 20.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 56/3493\n",
            "\n",
            "0: 384x640 12 persons, 22.5ms\n",
            "Speed: 1.9ms preprocess, 22.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 57/3493\n",
            "\n",
            "0: 384x640 13 persons, 21.2ms\n",
            "Speed: 2.2ms preprocess, 21.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 58/3493\n",
            "\n",
            "0: 384x640 12 persons, 19.8ms\n",
            "Speed: 1.9ms preprocess, 19.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 59/3493\n",
            "\n",
            "0: 384x640 12 persons, 22.1ms\n",
            "Speed: 2.2ms preprocess, 22.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 60/3493\n",
            "\n",
            "0: 384x640 13 persons, 20.3ms\n",
            "Speed: 2.6ms preprocess, 20.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 61/3493\n",
            "\n",
            "0: 384x640 14 persons, 19.9ms\n",
            "Speed: 2.8ms preprocess, 19.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 62/3493\n",
            "\n",
            "0: 384x640 14 persons, 21.1ms\n",
            "Speed: 1.9ms preprocess, 21.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 63/3493\n",
            "\n",
            "0: 384x640 13 persons, 20.4ms\n",
            "Speed: 1.9ms preprocess, 20.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 64/3493\n",
            "\n",
            "0: 384x640 13 persons, 20.9ms\n",
            "Speed: 2.2ms preprocess, 20.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 65/3493\n",
            "\n",
            "0: 384x640 13 persons, 21.1ms\n",
            "Speed: 2.1ms preprocess, 21.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 66/3493\n",
            "\n",
            "0: 384x640 14 persons, 20.6ms\n",
            "Speed: 1.9ms preprocess, 20.6ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 67/3493\n",
            "\n",
            "0: 384x640 13 persons, 21.3ms\n",
            "Speed: 2.3ms preprocess, 21.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 68/3493\n",
            "\n",
            "0: 384x640 13 persons, 20.4ms\n",
            "Speed: 2.1ms preprocess, 20.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 69/3493\n",
            "\n",
            "0: 384x640 13 persons, 20.2ms\n",
            "Speed: 1.9ms preprocess, 20.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 70/3493\n",
            "\n",
            "0: 384x640 13 persons, 20.8ms\n",
            "Speed: 1.8ms preprocess, 20.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 71/3493\n",
            "\n",
            "0: 384x640 11 persons, 20.3ms\n",
            "Speed: 2.0ms preprocess, 20.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 72/3493\n",
            "\n",
            "0: 384x640 11 persons, 21.4ms\n",
            "Speed: 2.0ms preprocess, 21.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 73/3493\n",
            "\n",
            "0: 384x640 11 persons, 22.2ms\n",
            "Speed: 2.0ms preprocess, 22.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 74/3493\n",
            "\n",
            "0: 384x640 11 persons, 19.8ms\n",
            "Speed: 1.9ms preprocess, 19.8ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 75/3493\n",
            "\n",
            "0: 384x640 12 persons, 20.4ms\n",
            "Speed: 1.8ms preprocess, 20.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 76/3493\n",
            "\n",
            "0: 384x640 10 persons, 20.2ms\n",
            "Speed: 1.8ms preprocess, 20.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 77/3493\n",
            "\n",
            "0: 384x640 12 persons, 19.5ms\n",
            "Speed: 2.7ms preprocess, 19.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 78/3493\n",
            "\n",
            "0: 384x640 12 persons, 20.9ms\n",
            "Speed: 2.1ms preprocess, 20.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 79/3493\n",
            "\n",
            "0: 384x640 11 persons, 21.0ms\n",
            "Speed: 2.1ms preprocess, 21.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 80/3493\n",
            "\n",
            "0: 384x640 12 persons, 20.6ms\n",
            "Speed: 2.0ms preprocess, 20.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 81/3493\n",
            "\n",
            "0: 384x640 10 persons, 20.1ms\n",
            "Speed: 1.8ms preprocess, 20.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 82/3493\n",
            "\n",
            "0: 384x640 10 persons, 20.3ms\n",
            "Speed: 2.0ms preprocess, 20.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 83/3493\n",
            "\n",
            "0: 384x640 10 persons, 22.4ms\n",
            "Speed: 2.1ms preprocess, 22.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 84/3493\n",
            "\n",
            "0: 384x640 11 persons, 21.0ms\n",
            "Speed: 2.3ms preprocess, 21.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 85/3493\n",
            "\n",
            "0: 384x640 12 persons, 20.4ms\n",
            "Speed: 2.0ms preprocess, 20.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 86/3493\n",
            "\n",
            "0: 384x640 11 persons, 20.1ms\n",
            "Speed: 1.9ms preprocess, 20.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 87/3493\n",
            "\n",
            "0: 384x640 12 persons, 19.7ms\n",
            "Speed: 2.9ms preprocess, 19.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 88/3493\n",
            "\n",
            "0: 384x640 10 persons, 19.0ms\n",
            "Speed: 1.9ms preprocess, 19.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 89/3493\n",
            "\n",
            "0: 384x640 11 persons, 19.0ms\n",
            "Speed: 2.0ms preprocess, 19.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 90/3493\n",
            "\n",
            "0: 384x640 12 persons, 20.4ms\n",
            "Speed: 2.8ms preprocess, 20.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 91/3493\n",
            "\n",
            "0: 384x640 13 persons, 19.7ms\n",
            "Speed: 2.2ms preprocess, 19.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 92/3493\n",
            "\n",
            "0: 384x640 14 persons, 19.2ms\n",
            "Speed: 1.9ms preprocess, 19.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 93/3493\n",
            "\n",
            "0: 384x640 14 persons, 19.8ms\n",
            "Speed: 2.0ms preprocess, 19.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 94/3493\n",
            "\n",
            "0: 384x640 15 persons, 20.4ms\n",
            "Speed: 2.6ms preprocess, 20.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 95/3493\n",
            "\n",
            "0: 384x640 16 persons, 19.1ms\n",
            "Speed: 1.9ms preprocess, 19.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 96/3493\n",
            "\n",
            "0: 384x640 15 persons, 22.3ms\n",
            "Speed: 2.6ms preprocess, 22.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 97/3493\n",
            "\n",
            "0: 384x640 14 persons, 19.4ms\n",
            "Speed: 2.0ms preprocess, 19.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 98/3493\n",
            "\n",
            "0: 384x640 13 persons, 21.2ms\n",
            "Speed: 1.8ms preprocess, 21.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 99/3493\n",
            "\n",
            "0: 384x640 15 persons, 20.3ms\n",
            "Speed: 1.9ms preprocess, 20.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 100/3493\n",
            "\n",
            "0: 384x640 14 persons, 19.9ms\n",
            "Speed: 2.0ms preprocess, 19.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 101/3493\n",
            "\n",
            "0: 384x640 14 persons, 20.2ms\n",
            "Speed: 1.9ms preprocess, 20.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 102/3493\n",
            "\n",
            "0: 384x640 15 persons, 20.4ms\n",
            "Speed: 2.0ms preprocess, 20.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 103/3493\n",
            "\n",
            "0: 384x640 14 persons, 18.9ms\n",
            "Speed: 2.0ms preprocess, 18.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 104/3493\n",
            "\n",
            "0: 384x640 13 persons, 20.3ms\n",
            "Speed: 2.1ms preprocess, 20.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 105/3493\n",
            "\n",
            "0: 384x640 12 persons, 20.2ms\n",
            "Speed: 1.8ms preprocess, 20.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 106/3493\n",
            "\n",
            "0: 384x640 12 persons, 20.1ms\n",
            "Speed: 1.9ms preprocess, 20.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 107/3493\n",
            "\n",
            "0: 384x640 13 persons, 20.3ms\n",
            "Speed: 2.0ms preprocess, 20.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 108/3493\n",
            "\n",
            "0: 384x640 13 persons, 20.3ms\n",
            "Speed: 2.1ms preprocess, 20.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 109/3493\n",
            "\n",
            "0: 384x640 13 persons, 19.8ms\n",
            "Speed: 2.1ms preprocess, 19.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 110/3493\n",
            "\n",
            "0: 384x640 12 persons, 20.6ms\n",
            "Speed: 2.1ms preprocess, 20.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 111/3493\n",
            "\n",
            "0: 384x640 12 persons, 19.1ms\n",
            "Speed: 2.3ms preprocess, 19.1ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 112/3493\n",
            "\n",
            "0: 384x640 14 persons, 22.5ms\n",
            "Speed: 2.7ms preprocess, 22.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 113/3493\n",
            "\n",
            "0: 384x640 14 persons, 20.4ms\n",
            "Speed: 2.1ms preprocess, 20.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 114/3493\n",
            "\n",
            "0: 384x640 15 persons, 20.6ms\n",
            "Speed: 1.9ms preprocess, 20.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 115/3493\n",
            "\n",
            "0: 384x640 14 persons, 19.7ms\n",
            "Speed: 2.0ms preprocess, 19.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 116/3493\n",
            "\n",
            "0: 384x640 13 persons, 22.5ms\n",
            "Speed: 2.0ms preprocess, 22.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 117/3493\n",
            "\n",
            "0: 384x640 15 persons, 20.4ms\n",
            "Speed: 2.1ms preprocess, 20.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 118/3493\n",
            "\n",
            "0: 384x640 16 persons, 21.7ms\n",
            "Speed: 2.0ms preprocess, 21.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 119/3493\n",
            "\n",
            "0: 384x640 15 persons, 19.7ms\n",
            "Speed: 1.9ms preprocess, 19.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 120/3493\n",
            "\n",
            "0: 384x640 14 persons, 21.1ms\n",
            "Speed: 2.6ms preprocess, 21.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 121/3493\n",
            "\n",
            "0: 384x640 13 persons, 20.2ms\n",
            "Speed: 1.9ms preprocess, 20.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 122/3493\n",
            "\n",
            "0: 384x640 14 persons, 20.9ms\n",
            "Speed: 2.1ms preprocess, 20.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 123/3493\n",
            "\n",
            "0: 384x640 15 persons, 21.1ms\n",
            "Speed: 2.1ms preprocess, 21.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 124/3493\n",
            "\n",
            "0: 384x640 14 persons, 21.7ms\n",
            "Speed: 2.0ms preprocess, 21.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 125/3493\n",
            "\n",
            "0: 384x640 14 persons, 21.1ms\n",
            "Speed: 1.9ms preprocess, 21.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 126/3493\n",
            "\n",
            "0: 384x640 14 persons, 20.5ms\n",
            "Speed: 1.8ms preprocess, 20.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 127/3493\n",
            "\n",
            "0: 384x640 14 persons, 20.4ms\n",
            "Speed: 2.4ms preprocess, 20.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 128/3493\n",
            "\n",
            "0: 384x640 14 persons, 20.2ms\n",
            "Speed: 1.9ms preprocess, 20.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 129/3493\n",
            "\n",
            "0: 384x640 16 persons, 20.4ms\n",
            "Speed: 1.8ms preprocess, 20.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 130/3493\n",
            "\n",
            "0: 384x640 16 persons, 20.7ms\n",
            "Speed: 1.9ms preprocess, 20.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 131/3493\n",
            "\n",
            "0: 384x640 17 persons, 21.8ms\n",
            "Speed: 2.0ms preprocess, 21.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 132/3493\n",
            "\n",
            "0: 384x640 17 persons, 21.0ms\n",
            "Speed: 2.2ms preprocess, 21.0ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 133/3493\n",
            "\n",
            "0: 384x640 17 persons, 20.7ms\n",
            "Speed: 2.0ms preprocess, 20.7ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 134/3493\n",
            "\n",
            "0: 384x640 15 persons, 20.2ms\n",
            "Speed: 1.8ms preprocess, 20.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 135/3493\n",
            "\n",
            "0: 384x640 12 persons, 20.3ms\n",
            "Speed: 2.1ms preprocess, 20.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 136/3493\n",
            "\n",
            "0: 384x640 13 persons, 20.3ms\n",
            "Speed: 2.0ms preprocess, 20.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 137/3493\n",
            "\n",
            "0: 384x640 12 persons, 21.3ms\n",
            "Speed: 2.6ms preprocess, 21.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 138/3493\n",
            "\n",
            "0: 384x640 12 persons, 21.1ms\n",
            "Speed: 1.8ms preprocess, 21.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 139/3493\n",
            "\n",
            "0: 384x640 13 persons, 20.4ms\n",
            "Speed: 2.1ms preprocess, 20.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 140/3493\n",
            "\n",
            "0: 384x640 12 persons, 20.3ms\n",
            "Speed: 2.6ms preprocess, 20.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 141/3493\n",
            "\n",
            "0: 384x640 12 persons, 19.8ms\n",
            "Speed: 2.7ms preprocess, 19.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 142/3493\n",
            "\n",
            "0: 384x640 10 persons, 21.6ms\n",
            "Speed: 2.1ms preprocess, 21.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 143/3493\n",
            "\n",
            "0: 384x640 12 persons, 21.1ms\n",
            "Speed: 2.2ms preprocess, 21.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 144/3493\n",
            "\n",
            "0: 384x640 14 persons, 19.4ms\n",
            "Speed: 1.9ms preprocess, 19.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 145/3493\n",
            "\n",
            "0: 384x640 12 persons, 20.2ms\n",
            "Speed: 3.0ms preprocess, 20.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 146/3493\n",
            "\n",
            "0: 384x640 13 persons, 19.6ms\n",
            "Speed: 1.9ms preprocess, 19.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 147/3493\n",
            "\n",
            "0: 384x640 13 persons, 20.1ms\n",
            "Speed: 2.0ms preprocess, 20.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 148/3493\n",
            "\n",
            "0: 384x640 12 persons, 20.3ms\n",
            "Speed: 2.1ms preprocess, 20.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 149/3493\n",
            "\n",
            "0: 384x640 14 persons, 21.7ms\n",
            "Speed: 2.1ms preprocess, 21.7ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 150/3493\n",
            "\n",
            "0: 384x640 13 persons, 20.9ms\n",
            "Speed: 1.9ms preprocess, 20.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 151/3493\n",
            "\n",
            "0: 384x640 12 persons, 20.1ms\n",
            "Speed: 2.1ms preprocess, 20.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 152/3493\n",
            "\n",
            "0: 384x640 13 persons, 20.3ms\n",
            "Speed: 1.8ms preprocess, 20.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 153/3493\n",
            "\n",
            "0: 384x640 11 persons, 22.9ms\n",
            "Speed: 2.4ms preprocess, 22.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 154/3493\n",
            "\n",
            "0: 384x640 11 persons, 19.7ms\n",
            "Speed: 1.9ms preprocess, 19.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 155/3493\n",
            "\n",
            "0: 384x640 12 persons, 19.7ms\n",
            "Speed: 1.9ms preprocess, 19.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 156/3493\n",
            "\n",
            "0: 384x640 15 persons, 20.0ms\n",
            "Speed: 2.7ms preprocess, 20.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 157/3493\n",
            "\n",
            "0: 384x640 11 persons, 20.8ms\n",
            "Speed: 2.5ms preprocess, 20.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 158/3493\n",
            "\n",
            "0: 384x640 15 persons, 20.4ms\n",
            "Speed: 2.5ms preprocess, 20.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 159/3493\n",
            "\n",
            "0: 384x640 17 persons, 20.4ms\n",
            "Speed: 2.0ms preprocess, 20.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 160/3493\n",
            "\n",
            "0: 384x640 17 persons, 19.4ms\n",
            "Speed: 2.0ms preprocess, 19.4ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 161/3493\n",
            "\n",
            "0: 384x640 15 persons, 20.1ms\n",
            "Speed: 1.8ms preprocess, 20.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 162/3493\n",
            "\n",
            "0: 384x640 16 persons, 22.0ms\n",
            "Speed: 2.6ms preprocess, 22.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 163/3493\n",
            "\n",
            "0: 384x640 15 persons, 21.0ms\n",
            "Speed: 2.1ms preprocess, 21.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 164/3493\n",
            "\n",
            "0: 384x640 15 persons, 21.8ms\n",
            "Speed: 2.7ms preprocess, 21.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 165/3493\n",
            "\n",
            "0: 384x640 16 persons, 21.1ms\n",
            "Speed: 2.6ms preprocess, 21.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 166/3493\n",
            "\n",
            "0: 384x640 16 persons, 20.6ms\n",
            "Speed: 1.9ms preprocess, 20.6ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 167/3493\n",
            "\n",
            "0: 384x640 16 persons, 20.2ms\n",
            "Speed: 1.9ms preprocess, 20.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Processed frame 168/3493\n",
            "\n",
            "0: 384x640 15 persons, 20.0ms\n",
            "Speed: 1.9ms preprocess, 20.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n"
          ]
        }
      ],
      "source": [
        "def detect_head_and_leg(video_path, output_video_path, model):\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error: Couldn't open video.\")\n",
        "        return\n",
        "\n",
        "    # Get video properties\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Define the codec and create VideoWriter object\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "    frame_count = 0\n",
        "    while cap.isOpened():\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        \n",
        "        results, legs_and_heads, boxes = process_detection_results(model, frame)\n",
        "\n",
        "        detections = sv.Detections.from_ultralytics(results)\n",
        "        detections = tracker.update_with_detections(detections)\n",
        "\n",
        "        depth_map = depth_anything.infer_image(frame)\n",
        "\n",
        "        for detection_idx, _ in enumerate(detections):\n",
        "            xyxy = detections[detection_idx].xyxy.tolist()[0]\n",
        "            obj_id = detections[detection_idx].tracker_id\n",
        "\n",
        "            best_idx = match(xyxy, boxes)\n",
        "\n",
        "\n",
        "            head_pos, leg_pos = legs_and_heads[best_idx]\n",
        "\n",
        "            #####\n",
        "            start, end = head_pos, leg_pos\n",
        "            length_pixels = np.sqrt((end[0] - start[0]) ** 2 + (end[1] - start[1]) ** 2)\n",
        "            middle_point = ((start[0] + end[0]) // 2, (start[1] + end[1]) // 2)\n",
        "\n",
        "            depth = depth_map[middle_point[1], middle_point[0]]\n",
        "            ##         \n",
        "\n",
        "           \n",
        "            obj_id =round (estimate_hight(length_pixels, depth, anchors), 2)\n",
        "\n",
        "\n",
        "            frame = annotate_frame(frame, head_pos, leg_pos, obj_id)\n",
        "       \n",
        "\n",
        "        # Display the frame\n",
        "        cv2.imshow('Frame', frame)\n",
        "\n",
        "        # Write the frame into the output video file\n",
        "        out.write(frame)\n",
        "\n",
        "        # Exit if 'Esc' key is pressed\n",
        "        if cv2.waitKey(1) & 0xFF == 27:  # 27 is the Esc key\n",
        "            break\n",
        "\n",
        "        frame_count += 1\n",
        "        print(f\"Processed frame {frame_count}/{total_frames}\")\n",
        "\n",
        "    # Release everything when finished\n",
        "    cap.release()\n",
        "    out.release()\n",
        "    \n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "output_video_path = 'output_video.mp4'\n",
        "\n",
        "\n",
        "detect_head_and_leg(VIDEO_PATH, output_video_path, model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
